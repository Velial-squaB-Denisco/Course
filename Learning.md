**Полный курс: Теория вероятностей и математическая статистика с нуля до эксперта**  
**Подробные уроки по каждой теме с примерами, кодом и заданиями**

---

### **Уровень 0: Математический фундамент**  
#### **Урок 0.1: Комбинаторика — искусство считать**  
**Цель**: Научиться считать варианты, даже если их миллионы.  

---

**Шаг 1: Правило умножения**  
**Понятие**: Если событие А может произойти `m` способами, а событие В — `n` способами, то оба события вместе — `m × n` способами.  
**Пример**:  
- У вас есть 3 футболки и 2 шорты. Сколько комбинаций нарядов?  
  **Решение**: 3 × 2 = 6.  

**Практика**:  
- Сколько паролей из 3 цифр можно создать? (Ответ: 10 × 10 × 10 = 1000).  

---

**Шаг 2: Перестановки (когда порядок важен)**  
**Понятие**: Число способов упорядочить `n` объектов: `n!` (n-факториал).  
**Пример**:  
- Сколько способов расставить 4 книги на полке?  
  **Решение**: 4! = 4 × 3 × 2 × 1 = 24.  

**Формула**:  
\[ n! = n \times (n-1) \times ... \times 1 \]  

**Практика**:  
- Сколько анаграмм у слова "КОТ"? (Ответ: 3! = 6: КОТ, КТО, ОКТ, ОТК, ТКО, ТОК).  

---

**Шаг 3: Сочетания (когда порядок НЕ важен)**  
**Понятие**: Число способов выбрать `k` объектов из `n` без учёта порядка:  
\[ C(n, k) = \frac{n!}{k! \times (n - k)!} \]  

**Пример**:  
- Сколько способов выбрать 2 книги из 5?  
  **Решение**: C(5, 2) = 10.  

**Практика**:  
- В лотерее 50 билетов, 5 выигрышных. Сколько комбинаций из 2 выигрышных билетов? (Ответ: C(5, 2) = 10).  

**Код**:  
```python
from math import comb
print(comb(5, 2))  # Ответ: 10
```

---

#### **Урок 0.2: Основы анализа — язык математики**  
**Цель**: Понять, как работают пределы, интегралы и ряды.  

---

**Шаг 1: Пределы — приближение к точке**  
**Понятие**: Предел функции при `x → a` — значение, к которому стремится функция.  
**Пример**:  
- \(\lim_{x \to 2} (x + 3) = 5\).  

**Практика**:  
- Чему равен \(\lim_{x \to 0} \frac{\sin(x)}{x}\)? (Ответ: 1).  

---

**Шаг 2: Интегралы — площадь под кривой**  
**Понятие**: Интеграл от функции — площадь между её графиком и осью X.  
**Пример**:  
- Интеграл от \(f(x) = 2x\) от 0 до 2:  
  \[ \int_{0}^{2} 2x \, dx = x^2 \bigg|_{0}^{2} = 4 - 0 = 4. \]  

**Практика**:  
- Чему равен \(\int_{0}^{1} x^2 \, dx\)? (Ответ: \(\frac{1}{3}\)).  

---

**Шаг 3: Ряды — сумма бесконечных чисел**  
**Понятие**: Ряд — сумма членов последовательности.  
**Пример**:  
- Геометрический ряд: \(1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + ... = 2\).  

**Формула**:  
\[ \sum_{n=0}^{\infty} ar^n = \frac{a}{1 - r}, \text{ если } |r| < 1. \]  

**Практика**:  
- Чему равна сумма \(1 + \frac{1}{3} + \frac{1}{9} + \frac{1}{27} + ...\)? (Ответ: \(\frac{3}{2}\)).  

---

### **Уровень 1: Основы вероятности**  
#### **Урок 1.1: Классическая вероятность — от кубиков до лотерей**  
**Цель**: Научиться считать шансы, как профессиональный игрок.  

---

**Шаг 1: Пространство элементарных исходов**  
**Понятие**: Все возможные исходы эксперимента.  
**Пример**:  
- Бросок кубика: {1, 2, 3, 4, 5, 6}.  

**Практика**:  
- Сколько исходов у эксперимента "2 броска монеты"? (Ответ: 4: ОО, ОР, РО, РР).  

---

**Шаг 2: Вероятность события**  
**Понятие**: Вероятность = Число благоприятных исходов / Общее число исходов.  
**Пример**:  
- Вероятность выпадения чётного числа на кубике: 3/6 = 0.5.  

**Формула**:  
\[ P(A) = \frac{\text{Число исходов в А}}{\text{Общее число исходов}} \]  

**Практика**:  
- В колоде 52 карты. Какова вероятность вытащить туза? (Ответ: 4/52 ≈ 0.077).  

---

**Шаг 3: Условная вероятность**  
**Понятие**: Вероятность события А при условии, что произошло событие В.  
**Формула**:  
\[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]  

**Пример**:  
- В коробке 3 красных и 2 синих шара. Вытащили красный шар. Какова вероятность, что следующий шар тоже красный?  
  **Решение**:  
  - После первого красного осталось 2 красных и 2 синих.  
  - Вероятность: 2/4 = 0.5.  

**Практика**:  
- В группе 60% девушек и 40% юношей. 30% девушек знают Python. Какова вероятность, что случайно выбранный человек — девушка, знающая Python? (Ответ: 0.6 × 0.3 = 0.18).  

---

#### **Урок 1.2: Парадоксы — когда интуиция обманывает**  
**Цель**: Понять, почему даже гении ошибаются в вероятностях.  

---

**Шаг 1: Парадокс Монти Холла**  
**Суть**: В игре с 3 дверьми (1 приз, 2 козы) ведущий открывает одну из козьих дверей после вашего выбора. Стоит ли менять дверь?  

**Решение**:  
- Шанс изначально выбрать приз: 1/3.  
- Если поменять выбор: шанс выиграть = 2/3.  

**Код**:  
```python
import random

wins = 0
total = 100000
for _ in range(total):
    doors = [0, 0, 1]  # 0 = коза, 1 = авто
    random.shuffle(doors)
    choice = random.randint(0, 2)
    # Ведущий открывает дверь с козой
    monty = next(i for i in range(3) if i != choice and doors[i] == 0)
    # Меняем выбор
    new_choice = next(i for i in range(3) if i != choice and i != monty)
    if doors[new_choice] == 1:
        wins += 1

print(f"Шанс выиграть при смене двери: {wins / total:.2f}")  # ≈ 0.67
```

**Практика**:  
- Проведите 1000 экспериментов с выбором "не менять дверь". Каков шанс выиграть? (Ответ: ≈ 1/3).  

---

**Шаг 2: Парадокс дней рождений**  
**Вопрос**: Сколько человек нужно, чтобы вероятность совпадения дней рождений была >50%?  

**Ответ**: 23 человека. Вероятность ≈ 50.7%.  

**Формула**:  
\[ P(n) = 1 - \frac{365!}{(365 - n)! \times 365^n} \]  

**Код**:  
```python
def birthday_probability(n):
    prob = 1.0
    for i in range(n):
        prob *= (365 - i) / 365
    return 1 - prob

print(f"Для 23 человек: {birthday_probability(23):.3f}")  # ≈ 0.507
```

**Практика**:  
- Для 40 человек вероятность ≈ 89%. Проверьте это через код.  

---

### **Уровень 2: Случайные величины и распределения**  
#### **Урок 2.1: Дискретные распределения — от монет до Пуассона**  
**Цель**: Научиться моделировать случайные события, как казино.  

---

**Шаг 1: Биномиальное распределение**  
**Понятие**: Число успехов в `n` независимых испытаниях с вероятностью `p`.  
**Формула**:  
\[ P(X = k) = C(n, k) \times p^k \times (1 - p)^{n - k} \]  

**Пример**:  
- Вероятность выпадения 3 орлов в 5 бросках:  
  \[ P(X = 3) = C(5, 3) \times 0.5^3 \times 0.5^2 = 10 \times 0.125 \times 0.25 = 0.3125. \]  

**Код**:  
```python
from scipy.stats import binom
n, p = 5, 0.5
print(f"P(X=3): {binom.pmf(3, n, p):.4f}")  # 0.3125
```

**Практика**:  
- Какова вероятность получить 2 шестёрки при 4 бросках кубика? (Ответ: ≈ 0.1157).  

---

**Шаг 2: Распределение Пуассона**  
**Понятие**: Моделирует редкие события (например, число звонков в кол-центр за час).  
**Формула**:  
\[ P(X = k) = \frac{\lambda^k \times e^{-\lambda}}{k!} \]  

**Пример**:  
- Если в магазин в среднем приходит 5 клиентов в час, какова вероятность прихода 3 клиентов?  
  \[ P(X = 3) = \frac{5^3 \times e^{-5}}{3!} ≈ 0.1404. \]  

**Код**:  
```python
from scipy.stats import poisson
lambda_param = 5
print(f"P(X=3): {poisson.pmf(3, lambda_param):.4f}")  # 0.1404
```

**Практика**:  
- Если λ = 2, найдите P(X=0). (Ответ: ≈ 0.1353).  

---

**Шаг 3: Гипергеометрическое распределение**  
**Понятие**: Вероятность выбрать `k` успехов без возвращения.  
**Формула**:  
\[ P(X = k) = \frac{C(K, k) \times C(N-K, n-k)}{C(N, n)} \]  

**Пример**:  
- В колоде 4 туза. Какова вероятность вытащить 2 туза из 5 карт?  
  \[ P(X=2) = \frac{C(4, 2) \times C(48, 3)}{C(52, 5)} ≈ 0.0399. \]  

**Код**:  
```python
from scipy.stats import hypergeom
N, K, n = 52, 4, 5
print(f"P(X=2): {hypergeom.pmf(2, N, K, n):.4f}")  # 0.0399
```

**Практика**:  
- В корзине 10 яблок, 3 гнилых. Какова вероятность выбрать 1 гнилое из 4? (Ответ: ≈ 0.5000).  

---

#### **Урок 2.2: Непрерывные распределения — время, рост и ошибки**  
**Цель**: Понять, как распределены непрерывные величины (например, рост людей).  

---

**Шаг 1: Равномерное распределение**  
**Понятие**: Все значения в интервале [a, b] равновероятны.  
**Формула плотности**:  
\[ f(x) = \frac{1}{b - a} \text{ для } x \in [a, b]. \]  

**Пример**:  
- Автобус приходит каждые 10 минут. Какова вероятность ждать меньше 3 минут?  
  **Решение**: Площадь прямоугольника [0, 3] высотой 0.1: 3 × 0.1 = 0.3.  

**Код**:  
```python
from scipy.stats import uniform
a, b = 0, 10
print(f"P(X < 3): {uniform.cdf(3, a, b):.2f}")  # 0.30
```

**Практика**:  
- Если время ожидания равномерно на [0, 20], найдите P(5 < X < 15). (Ответ: 0.5).  

---

**Шаг 2: Нормальное распределение**  
**Понятие**: Колоколообразная кривая, описывающая многие природные явления.  
**Формула плотности**:  
\[ f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - \mu)^2}{2\sigma^2}} \]  

**Пример**:  
- Рост мужчин: μ = 175 см, σ = 10 см.  
- Какой процент мужчин выше 190 см?  
  **Решение**:  
  - 190 = μ + 1.5σ.  
  - По правилу 68-95-99.7, выше μ + 2σ — 2.5%, но точнее через Z-таблицы: ≈ 6.68%.  

**Код**:  
```python
from scipy.stats import norm
mu, sigma = 175, 10
prob = 1 - norm.cdf(190, mu, sigma)
print(f"Процент выше 190 см: {prob:.4f}")  # ≈ 0.0668
```

**Практика**:  
- Если IQ ~ N(100, 15), найдите P(85 < X < 115). (Ответ: ≈ 68%).  

---

**Шаг 3: Экспоненциальное распределение**  
**Понятие**: Моделирует время между событиями (например, звонками).  
**Формула плотности**:  
\[ f(x) = \lambda e^{-\lambda x} \text{ для } x \geq 0. \]  

**Пример**:  
- Среднее время между звонками — 10 минут (λ = 1/10).  
- Какова вероятность, что следующий звонок через 5 минут?  
  **Решение**:  
  \[ P(X > 5) = e^{-5/10} ≈ 0.6065. \]  

**Код**:  
```python
from scipy.stats import expon
lambda_param = 1/10
print(f"P(X > 5): {expon.sf(5, scale=1/lambda_param):.4f}")  # 0.6065
```

**Практика**:  
- Если λ = 0.2, найдите P(X < 3). (Ответ: ≈ 0.4512).  

---

### **Уровень 3: Статистика — анализ данных**  
#### **Урок 3.1: Описательная статистика — числа рассказывают историю**  
**Цель**: Научиться описывать данные несколькими числами.  

---

**Шаг 1: Меры центральной тенденции**  
- **Среднее**: \(\bar{x} = \frac{1}{n} \sum x_i\).  
- **Медиана**: Среднее значение в упорядоченном ряду.  
- **Мода**: Наиболее частое значение.  

**Пример**:  
- Данные: [2, 3, 5, 7, 11].  
  - Среднее: (2 + 3 + 5 + 7 + 11)/5 = 5.6.  
  - Медиана: 5.  
  - Мода: нет.  

**Код**:  
```python
data = [2, 3, 5, 7, 11]
print(f"Среднее: {np.mean(data)}")    # 5.6
print(f"Медиана: {np.median(data)}") # 5.0
print(f"Мода: {pd.Series(data).mode()[0]}")  # Ошибка: нет моды
```

**Практика**:  
- Для данных [1, 2, 2, 3, 4] найдите моду. (Ответ: 2).  

---

**Шаг 2: Меры разброса**  
- **Дисперсия**: \(\sigma^2 = \frac{1}{n} \sum (x_i - \bar{x})^2\).  
- **Стандартное отклонение**: \(\sigma = \sqrt{\sigma^2}\).  
- **Межквартильный размах (IQR)**: Q3 - Q1.  

**Пример**:  
- Данные: [1, 2, 4, 7].  
  - Дисперсия: ((1-3.5)² + (2-3.5)² + (4-3.5)² + (7-3.5)²) / 4 = 5.25.  
  - Стандартное отклонение: \(\sqrt{5.25} ≈ 2.29\).  

**Код**:  
```python
data = [1, 2, 4, 7]
print(f"Дисперсия: {np.var(data):.2f}")          # 5.25
print(f"Стандартное отклонение: {np.std(data):.2f}")  # 2.29
```

**Практика**:  
- Для данных [10, 20, 30] найдите дисперсию. (Ответ: 66.67).  

---

**Шаг 3: Визуализация данных**  
- **Гистограмма**: Показывает распределение данных.  
- **Ящик с усами (Boxplot)**: Отображает медиану, квартили и выбросы.  

**Пример**:  
```python
import seaborn as sns
data = np.random.normal(0, 1, 1000)
sns.histplot(data, kde=True)  # Гистограмма с ядерной оценкой
plt.title("Распределение данных")
plt.show()
```

**Практика**:  
- Постройте boxplot для данных [12, 15, 18, 22, 25, 28, 32].  

---

#### **Урок 3.2: Проверка гипотез — как принимать решения на основе данных**  
**Цель**: Научиться отличать случайные флуктуации от реальных эффектов.  

---

**Шаг 1: Нулевая и альтернативная гипотезы**  
- **Нулевая гипотеза (H₀)**: Нет эффекта (например, "средние двух групп равны").  
- **Альтернативная гипотеза (H₁)**: Эффект есть.  

**Пример**:  
- H₀: Новый препарат не эффективнее плацебо.  
- H₁: Препарат эффективнее.  

---

**Шаг 2: p-значение**  
**Понятие**: Вероятность получить наблюдаемые данные при условии, что H₀ верна.  
- Если p < 0.05 → отвергаем H₀.  

**Пример**:  
- p = 0.03 → Отвергаем H₀ на уровне значимости 5%.  

---

**Шаг 3: t-тест для сравнения средних**  
**Понятие**: Проверяет, различаются ли средние двух групп.  
**Пример**:  
- Группа A: [5, 6, 7, 8, 9] (среднее = 7).  
- Группа B: [3, 4, 5, 6, 7] (среднее = 5).  
- Есть ли статистически значимая разница?  

**Код**:  
```python
from scipy.stats import ttest_ind
group_a = [5, 6, 7, 8, 9]
group_b = [3, 4, 5, 6, 7]
t_stat, p_val = ttest_ind(group_a, group_b)
print(f"p-значение: {p_val:.4f}")  # ≈ 0.095
```

**Практика**:  
- Если p = 0.09, можно ли отвергнуть H₀ на уровне 5%? (Ответ: Нет).  

---

### **Уровень 4: Байесовская статистика**  
#### **Урок 4.1: Байесовский вывод — как обновлять убеждения**  
**Цель**: Научиться использовать априорные знания для анализа данных.  

---

**Шаг 1: Формула Байеса**  
\[ P(A|B) = \frac{P(B|A) \times P(A)}{P(B)} \] 
- **P(A)**: Априорная вероятность.  
- **P(B|A)**: Правдоподобие.  
- **P(A|B)**: Апостериорная вероятность.  

**Пример**:  
- Болезнь есть у 1% людей. Тест точность 95%. При положительном тесте вероятность болезни ≈ 16%.  

---

**Шаг 2: Сопряженные априоры**  
**Понятие**: Априор и апостериор принадлежат одному классу распределений.  
- Бета-распределение для вероятности.  
- Гамма-распределение для интенсивности.  

**Пример**:  
- Априор: Beta(α=1, β=1) → Равномерное распределение.  
- Данные: 7 успехов из 10 испытаний.  
- Апостериор: Beta(α=8, β=4).  

**Код**:  
```python
from scipy.stats import beta
prior = beta(1, 1)
posterior = beta(1 + 7, 1 + 3)
x = np.linspace(0, 1, 100)
plt.plot(x, prior.pdf(x), label='Априор')
plt.plot(x, posterior.pdf(x), label='Апостериор')
plt.legend()
plt.show()
```

**Практика**:  
- Если априор Beta(2, 2) и данные 5 успехов из 10, каков апостериор? (Ответ: Beta(7, 7)).  

---

#### **Урок 4.2: MCMC — как моделировать сложные распределения**  
**Цель**: Научиться работать с нестандартными моделями.  

---

**Шаг 1: Алгоритм Метрополиса-Гастингса**  
1. Выберите начальное значение \(x_0\).  
2. Предложите новое значение \(x'\) из распределения-кандидата.  
3. Примите \(x'\) с вероятностью \(\min\left(1, \frac{P(x')}{P(x)}\right)\).  

**Пример**:  
- Оценка среднего нормального распределения.  

---

**Шаг 2: Реализация на Python**  
```python
import numpy as np
from scipy.stats import norm

# Целевое распределение: N(3, 2)
def target(x):
    return norm.pdf(x, loc=3, scale=2)

# Алгоритм Метрополиса
samples = []
current = 0.0
for _ in range(10000):
    proposal = current + np.random.normal(0, 1)
    acceptance_ratio = target(proposal) / target(current)
    if np.random.rand() < acceptance_ratio:
        current = proposal
    samples.append(current)

print(f"Среднее: {np.mean(samples):.2f}")  # ≈ 3.0
```

**Практика**:  
- Измените параметры нормального распределения и проверьте результат.  

---

### **Уровень 5: Машинное обучение**  
#### **Урок 5.1: Линейная регрессия — предсказание чисел**  
**Цель**: Научиться предсказывать цены, продажи и другие величины.  

---

**Шаг 1: Формула линейной регрессии**  
\[ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \epsilon \]  
- **Цель**: Найти коэффициенты \(\beta\), минимизирующие ошибку.  

**Пример**:  
- Предсказание цены дома на основе площади.  

**Код**:  
```python
from sklearn.linear_model import LinearRegression
X = [[100], [150], [200]]  # Площадь
y = [300, 450, 600]        # Цена
model = LinearRegression()
model.fit(X, y)
print(f"Коэффициент: {model.coef_[0]:.2f}")  # 3.0 (цена за м²)
```

**Практика**:  
- Добавьте признак "количество комнат" и обучите модель.  

---

#### **Урок 5.2: Классификация — логистическая регрессия**  
**Цель**: Научиться предсказывать категории (спам/не спам).  

---

**Шаг 1: Сигмоидная функция**  
\[ P(y=1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}} \]  
- Выводит вероятность принадлежности к классу 1.  

**Пример**:  
- Предсказание вероятности дефолта по кредиту.  

**Код**:  
```python
from sklearn.linear_model import LogisticRegression
X = [[2000], [3000], [4000]]  # Зарплата
y = [0, 0, 1]                 # Дефолт (0 = нет, 1 = да)
model = LogisticRegression()
model.fit(X, y)
print(f"Вероятность дефолта для 2500$: {model.predict_proba([[2500]])[0][1]:.2f}")
```

**Практика**:  
- Добавьте признак "возраст" и сравните результаты.  

---

### **Уровень 6: Экспертные темы**  
#### **Урок 6.1: Стохастические процессы — моделирование случайности во времени**  
**Цель**: Научиться предсказывать динамические системы (цены акций, погоду).  

---

**Шаг 1: Броуновское движение**  
**Понятие**: Случайное блуждание с непрерывным временем.  
**Пример**:  
- Моделирование цены акции:  
\[ S_t = S_0 \times e^{(μ - \frac{σ^2}{2})t + σW_t} \]  
где \(W_t\) — винеровский процесс.  

**Код**:  
```python
import numpy as np
import matplotlib.pyplot as plt

# Параметры модели
n_steps = 1000
t = np.linspace(0, 1, n_steps)
mu = 0.1    # Средняя доходность
sigma = 0.2 # Волатильность
S0 = 100    # Начальная цена

# Генерация броуновского движения
dW = np.random.normal(0, np.sqrt(1/n_steps), n_steps)
W = np.cumsum(dW)
S = S0 * np.exp((mu - 0.5*sigma**2)*t + sigma*W)

# Визуализация
plt.plot(t, S)
plt.title("Геометрическое броуновское движение")
plt.xlabel("Время")
plt.ylabel("Цена акции")
plt.show()
```

**Практика**:  
- Измените волатильность (σ) на 0.3. Как меняется график?  
- **Ответ**: График станет более «рваным» из-за увеличения случайных колебаний.

---

**Шаг 2: Пуассоновский процесс**  
**Понятие**: Моделирует редкие события (например, количество кликов на сайт за час).  
**Пример**:  
- Среднее число кликов в час: 5. Какова вероятность 3 кликов за час?  
\[ P(X=3) = \frac{5^3 e^{-5}}{3!} ≈ 0.1404. \]  

**Код**:  
```python
from scipy.stats import poisson
lambda_param = 5
print(f"P(X=3): {poisson.pmf(3, lambda_param):.4f}")  # 0.1404
```

**Практика**:  
- Для λ=10, найдите P(X=7). (Ответ: ≈ 0.0901).

---

### **Урок 6.2: Байесовские сети — моделирование сложных зависимостей**  
**Цель**: Научиться представлять зависимости между переменными.  

---

**Шаг 1: Пример медицинской диагностики**  
- Узлы: Болезнь (D), Симптом (S).  
- Связи: D → S.  

**Код**:  
```python
from pgmpy.models import BayesianModel
from pgmpy.factors.discrete import TabularCPD

# Создание модели
model = BayesianModel([('D', 'S')])

# Определение условных вероятностей
cpd_d = TabularCPD(variable='D', variable_card=2, values=[[0.99], [0.01]])  # 1% болезнь
cpd_s = TabularCPD(
    variable='S', 
    variable_card=2, 
    values=[[0.95, 0.01],  # P(S=0|D=0), P(S=0|D=1)
    evidence=['D'], 
    evidence_card=[2]
)

# Добавление CPD в модель
model.add_cpds(cpd_d, cpd_s)

# Проверка модели
print(model.check_model())
```

**Практика**:  
- Добавьте узел «Возраст» и свяжите его с «Болезнью». Как изменится сеть?

---

### **Дополнения из статьи на Хабре**  
#### **1. A/B-тестирование**  
**Шаг 1: Расчет мощности теста**  
- **Мощность**: Вероятность обнаружить эффект, если он есть.  
- **Инструменты**: Python-библиотеки `statsmodels`, `scipy`.  

**Код**:  
```python
from statsmodels.stats.power import TTestIndPower

# Параметры
effect_size = 0.5  # Средняя разница / стандартное отклонение
alpha = 0.05       # Уровень значимости
nobs1 = 100        # Размер выборки

# Расчет мощности
power = TTestIndPower().solve_power(effect_size, nobs1=nobs1, alpha=alpha)
print(f"Мощность теста: {power:.2f}")  # ≈ 0.8
```

**Практика**:  
- Увеличьте размер выборки до 200. Как изменится мощность? (Ответ: ≈ 0.97).

---

#### **2. Работа с большими данными**  
**Шаг 1: Ускорение кода через Numba**  
**Пример**: Оптимизация функции для подсчета суммы.  

**Код**:  
```python
from numba import njit
import numpy as np

@njit
def fast_sum(arr):
    total = 0
    for x in arr:
        total += x
    return total

data = np.random.rand(1_000_000)
print(fast_sum(data))  # Работает в 100 раз быстрее!
```

**Практика**:  
- Напишите функцию для подсчета среднего с использованием Numba.

---

### **Итоговый проект: Предсказание цен на жильё**  
**Цель**: Применить все изученные методы на реальных данных.  

---

**Шаг 1: Загрузка данных**  
```python
import pandas as pd
from sklearn.datasets import fetch_california_housing

data = fetch_california_housing()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['Price'] = data.target
print(df.head())
```

---

**Шаг 2: Анализ данных**  
- Постройте гистограммы для всех признаков.  
- Проверьте корреляцию между ценой и MedInc (средний доход).  

**Код**:  
```python
import seaborn as sns
sns.heatmap(df.corr(), annot=True)
plt.show()
```

---

**Шаг 3: Построение модели**  
```python
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X = df[['MedInc', 'HouseAge']]
y = df['Price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = LinearRegression()
model.fit(X_train, y_train)
print(f"R²: {model.score(X_test, y_test):.2f}")
```

---

**Шаг 4: Интерпретация результатов**  
- Коэффициент MedInc показывает, как цена зависит от дохода.  
- Например: \(\beta_{\text{MedInc}} = 0.4\) → Увеличение дохода на 1 → Рост цены на 0.4.

---

### **Заключение**  
Вы прошли путь от основ комбинаторики до сложных стохастических моделей!  
**Что дальше**:  
1. **Портфолио**: Выложите проекты на GitHub.  
2. **Соревнования**: Участвуйте в Kaggle.  
3. **Книги**:  
   - *«Теория вероятностей»* Гнеденко.  
   - *«Глубокое обучение»* Гудфеллоу.  

**Помните**:  
> «Статистика — это наука о том, как не попасться на удочку случайности».  
> — Анонимный статистик.

Удачи в освоении мира данных! 🚀
